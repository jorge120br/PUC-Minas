{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(16,3), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_excel('spare-parts-sales.xlsx', header=0, names=['item', 'sales', 'cost', 'date'], index_col=None, parse_dates=True, squeeze=True)\n",
    "\n",
    "series['date'] = pd.to_datetime(series['date'])\n",
    "date_filter = (series['date'] >= '2014-01-01') & (series['date'] <= '2016-11-30')\n",
    "series = series[date_filter]\n",
    "\n",
    "sku = '98550154'\n",
    "series = series[series.item == sku]\n",
    "\n",
    "series.drop(series.columns[[0, 2]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = (series.groupby(pd.Grouper(key='date',freq='w')).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação do dataset com lags\n",
    "values = DataFrame(series.values)\n",
    "dataframe = concat([values.shift(1), values], axis=1)\n",
    "dataframe.columns = ['t', 't+1']\n",
    "\n",
    "# dividir em conjuntos de treinamento e teste\n",
    "X = dataframe.values\n",
    "train_size = int(len(X) * 0.66)\n",
    "train, test = X[1:train_size], X[train_size:]\n",
    "train_X, train_y = train[:,0], train[:,1]\n",
    "test_X, test_y = test[:,0], test[:,1]\n",
    "\n",
    "# naive model no conjunto de teste\n",
    "train_pred = [x for x in train_X]\n",
    "\n",
    "# calcular residuos\n",
    "train_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]\n",
    "\n",
    "# modelar os resíduos do conjunto de treinamento\n",
    "window = 15\n",
    "model = AutoReg(train_resid, lags=window, old_names=True)\n",
    "model_fit = model.fit()\n",
    "coef = model_fit.params\n",
    "\n",
    "# walk forward ao longo do tempo, no conjunto de teste\n",
    "history = train_resid[len(train_resid)-window:]\n",
    "history = [history[i] for i in range(len(history))]\n",
    "predictions = list()\n",
    "for t in range(len(test_y)):\n",
    "    # naive\n",
    "    yhat = test_X[t]\n",
    "    error = test_y[t] - yhat\n",
    "    # predição do erro\n",
    "    length = len(history)\n",
    "    lag = [history[i] for i in range(length-window,length)]\n",
    "    pred_error = coef[0]\n",
    "    for d in range(window):\n",
    "        pred_error += coef[d+1] * lag[window-d-1]\n",
    "    # correção da predição\n",
    "    yhat = yhat + pred_error\n",
    "    predictions.append(yhat)\n",
    "    history.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do Modelo\n",
    "MAPE = mean_absolute_percentage_error(test_y, predictions)\n",
    "MAE = mean_absolute_error(test_y, predictions)\n",
    "MSE = mean_squared_error(test_y, predictions)\n",
    "R2 = r2_score(test_y,predictions)\n",
    "accuracy = 100 - MAPE\n",
    "print('Performance do Modelo')\n",
    "print('----------------------------')\n",
    "#print('Coeficiente de Determinação: {:0.2}.'.format(R2))\n",
    "print('Acurácia = {:0.2f} %.'.format(accuracy))\n",
    "print('MAPE = {:0.2f} %.'.format(MAPE))\n",
    "print('MAE = {:0.2f} Unidades.'.format(MAE))\n",
    "print('MSE = {:0.2f}.'.format(MSE))\n",
    "print('RMSE = {:0.2f}.'.format(sqrt(MSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação dos Resíduos\n",
    "residuals = [test_y[i]-predictions[i] for i in range(len(predictions))]\n",
    "residuals = DataFrame(residuals)\n",
    "print('Descrição dos Resíduos')\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com os valores de treino e teste\n",
    "original=np.concatenate((train_X, test_X), axis=0)\n",
    "plt.plot(original, label='Original')\n",
    "x = range((len(train_X)), (len(original)))\n",
    "plt.plot(x, predictions, label='Predicted')\n",
    "plt.title('Vendas de Peças de Reposição de 2014 a 2016')\n",
    "plt.xlabel('Meses')\n",
    "plt.ylabel('Quantidade Vendas')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-hopkins",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
